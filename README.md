<h1 align="center">NH·∫¨N DI·ªÜN KHU√îN M·∫∂T K·∫æT H·ª¢P V·ªöI KH·∫®U TRANG </h1>

<div align="center">

<p align="center">
  <img src="./image/logodnu.png" alt="DaiNam University Logo" width="200"/>
    <img src="./image/LogoAIoTLab.png" alt="AIoTLab Logo" width="170"/>
</p>

[![Made by AIoTLab](https://img.shields.io/badge/Made%20by%20AIoTLab-blue?style=for-the-badge)](https://www.facebook.com/DNUAIoTLab)
[![Fit DNU](https://img.shields.io/badge/Fit%20DNU-green?style=for-the-badge)](https://fitdnu.net/)
[![DaiNam University](https://img.shields.io/badge/DaiNam%20University-red?style=for-the-badge)](https://dainam.edu.vn)
</div>

<h2 align="center">S·ª≠ D·ª•ng 3D CNN ƒê·ªÉ Nh·∫≠n Di·ªán Khu√¥n M·∫∑t C√πng K·∫øt H·ª£p V·ªõi Kh·∫©u Trang</h2>

<p align="left">
Nh·∫≠n di·ªán khu√¥n m·∫∑t b·∫±ng 3D Convolutional Neural Network (3D CNN) l√† m·ªôt ·ª©ng d·ª•ng ti√™n ti·∫øn c·ªßa c√¥ng ngh·ªá AI trong vi·ªác ph√¢n t√≠ch v√† nh·∫≠n di·ªán khu√¥n m·∫∑t. C√¥ng ngh·ªá n√†y s·ª≠ d·ª•ng m·∫°ng n∆°-ron t√≠ch ch·∫≠p 3D ƒë·ªÉ ph√¢n t√≠ch c√°c ƒë·∫∑c ƒëi·ªÉm kh√¥ng gian v√† th·ªùi gian c·ªßa khu√¥n m·∫∑t, cho ph√©p h·ªá th·ªëng nh·∫≠n di·ªán ch√≠nh x√°c ngay c·∫£ khi c√≥ s·ª± thay ƒë·ªïi v·ªÅ √°nh s√°ng, g√≥c nh√¨n ho·∫∑c c√≥ v·∫≠t c·∫£n nh∆∞ kh·∫©u trang
</p>


<p align="left">
C√°ch th·ª©c ho·∫°t ƒë·ªông 3D CNN m·ªü r·ªông m·∫°ng CNN 2D truy·ªÅn th·ªëng b·∫±ng c√°ch th√™m m·ªôt chi·ªÅu th·ªùi gian ho·∫∑c chi·ªÅu s√¢u.
ƒê·∫ßu v√†o c·ªßa m·∫°ng l√† d·ªØ li·ªáu ·∫£nh 3D (bao g·ªìm th√¥ng tin v·ªÅ chi·ªÅu s√¢u v√† k·∫øt c·∫•u c·ªßa khu√¥n m·∫∑t).
M·ªói l·ªõp t√≠ch ch·∫≠p (convolutional layer) trong 3D CNN th·ª±c hi·ªán c√°c ph√©p t√≠nh tr√™n c·∫£ ba chi·ªÅu (chi·ªÅu cao, chi·ªÅu r·ªông v√† chi·ªÅu s√¢u) ƒë·ªÉ tr√≠ch xu·∫•t c√°c ƒë·∫∑c tr∆∞ng ph·ª©c t·∫°p h∆°n.
Sau khi qua c√°c l·ªõp t√≠ch ch·∫≠p v√† pooling, c√°c ƒë·∫∑c tr∆∞ng ƒë∆∞·ª£c ƒë∆∞a v√†o l·ªõp Fully Connected ƒë·ªÉ ph√¢n lo·∫°i ho·∫∑c x√°c ƒë·ªãnh danh t√≠nh khu√¥n m·∫∑t.
</p>


## üåü Gi·ªõi thi·ªáu
3D CNN (Three-Dimensional Convolutional Neural Network) l√† m·ªôt lo·∫°i m·∫°ng n∆°-ron t√≠ch ch·∫≠p (Convolutional Neural Network - CNN) ƒë∆∞·ª£c m·ªü r·ªông ƒë·ªÉ x·ª≠ l√Ω d·ªØ li·ªáu c√≥ th√™m chi·ªÅu th·ª© ba (depth). <br>
N·∫øu nh∆∞ CNN th√¥ng th∆∞·ªùng ch·ªâ ho·∫°t ƒë·ªông tr√™n d·ªØ li·ªáu 2D (chi·ªÅu r·ªông v√† chi·ªÅu cao), th√¨ 3D CNN m·ªü r·ªông ra th√†nh chi·ªÅu s√¢u ƒë·ªÉ x·ª≠ l√Ω d·ªØ li·ªáu c√≥ t√≠nh ch·∫•t kh√¥ng gian v√† th·ªùi gian.
<br>
---
## üèóÔ∏è H·ªÜ TH·ªêNG
<p align="center">
  <img src="./image/cbyolov7" alt="System Architecture" width="800"/>
</p>

---


## üõ†Ô∏è C√îNG NGH·ªÜ S·ª¨ D·ª§NG

<div align="center">

<p align="center">
  <img src="./image/CNN.png" alt="System Architecture" width="800"/>
</p>
</div>

- **Python**  
- **TensorFlow / PyTorch**  
- **OpenCV**  
- **NumPy**  
- **Matplotlib**  
##  Y√™u c·∫ßu h·ªá th·ªëng

-C√≥ th·ªÉ s·ª≠ d·ª•ng Visual n·∫øu m√°y ƒë·ªß kho·∫ª 
<br>
or
<br>
-S·ª≠ d·ª•ng <a href="https://colab.google/" target="_blank">Colab</a> cho nhanh

## üöÄ H∆∞·ªõng d·∫´n c√†i ƒë·∫∑t v√† ch·∫°y


 <h2>B∆∞·ªõc 1: Thu th·∫≠p d·ªØ li·ªáu</h2>
  <p> Thu th·∫≠p d·ªØ li·ªáu h√¨nh ·∫£nh ho·∫∑c video v·ªÅ khu√¥n m·∫∑t c√≥ v√† kh√¥ng c√≥ kh·∫©u trang.<br>
   C√≥ th·ªÉ s·ª≠ d·ª•ng c√°c b·ªô d·ªØ li·ªáu s·∫µn c√≥ nh∆∞ **MaskedFace-Net** ho·∫∑c **RMFD**.  
üëâ Dataset: [MaskedFace-Net](https://www.kaggle.com/laurentmih/maskedface-net)  
  </p>
    <h2>B∆∞·ªõc 2: Chu·∫©n b·ªã m√¥i tr∆∞·ªùng l√†m vi·ªác </h2>
    Tr√™n **Google Colab** ho·∫∑c m√°y t√≠nh c·ª•c b·ªô, c√†i ƒë·∫∑t c√°c th∆∞ vi·ªán c·∫ßn thi·∫øt:  
    
```bash
!pip install tensorflow keras opencv-python matplotlib numpy
```
   <p>Dataset </p><a href="https://universe.roboflow.com/ttnt-nyz2m/ai-fxy4m/dataset/2" target="_blank">T·∫°i ƒê√¢y</a> 
    <h2>B∆∞·ªõc 3:  X√¢y d·ª±ng m√¥ h√¨nh 3D CNN</h2>
    <p>ƒê·ªÉ t·∫£i d·ªØ li·ªáu l√™n Google Drive, b·∫°n c√≥ th·ªÉ s·ª≠ d·ª•ng giao di·ªán web ho·∫∑c API.</p>
    
    import tensorflow as tf
    from tensorflow.keras import layers, models
    model = models.Sequential()
    
    # Layer t√≠ch ch·∫≠p 3D
    model.add(layers.Conv3D(32, (3, 3, 3), activation='relu', input_shape=(64, 64, 30, 1)))
    model.add(layers.MaxPooling3D((2, 2, 2)))
    
    model.add(layers.Conv3D(64, (3, 3, 3), activation='relu'))
    model.add(layers.MaxPooling3D((2, 2, 2)))
    
    model.add(layers.Conv3D(128, (3, 3, 3), activation='relu'))
    model.add(layers.MaxPooling3D((2, 2, 2)))
    
    # Flatten v√† Fully Connected Layer
    model.add(layers.Flatten())
    model.add(layers.Dense(256, activation='relu'))
    model.add(layers.Dropout(0.5))
    model.add(layers.Dense(2, activation='softmax'))  # 2 l·ªõp ƒë·∫ßu ra: c√≥ v√† kh√¥ng c√≥ kh·∫©u trang

    # Compile model
    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])

    model.summary()

  <h2>B∆∞·ªõc 4:  Chu·∫©n b·ªã d·ªØ li·ªáu hu·∫•n luy·ªán </h2>
    <p>Truy c·∫≠p v√†o Google Colab ƒë·ªÉ th·ª±c hi·ªán hu·∫•n luy·ªán m√¥ h√¨nh 3D CNN.</p>
    <p>B·∫°n c√≥ th·ªÉ tham kh·∫£o Cobal c·ªßa ch√∫ng t√¥i ·ªü ƒë√¢y</p> <a 
    href="https://colab.research.google.com/drive/16UQlO2zOYBssLDlA1bMMzwgKP1V4yEBA#scrollTo=ncRjJBLV6AM_">T·∫°i ƒê√¢y</a> 
    
       import os
      import numpy as np
      from tensorflow.keras.preprocessing.image import load_img, img_to_array
      # T·∫°o d·ªØ li·ªáu t·ª´ c√°c th∆∞ m·ª•c
      def load_dataset(path):
          data = []
          labels = []
          for folder in os.listdir(path):
              for file in os.listdir(os.path.join(path, folder)):
                  img = load_img(os.path.join(path, folder, file), target_size=(64, 64))
                  img_array = img_to_array(img)
                  data.append(img_array)
                  labels.append(0 if folder == 'without_mask' else 1)
          return np.array(data), np.array(labels)
    X, y = load_dataset('/content/drive/MyDrive/dataset')
    X = X / 255.0

  <h2>B∆∞·ªõc 5: Hu·∫•n luy·ªán m√¥ h√¨nh</h2>
    <p>Hu·∫•n luy·ªán m√¥ h√¨nh v·ªõi d·ªØ li·ªáu ƒë√£ ƒë∆∞·ª£c x·ª≠ l√Ω </p>
    
     history = model.fit(X, y, epochs=30, batch_size=16, validation_split=0.2)

  <h2>B∆∞·ªõc 6: ƒê√°nh gi√° m√¥ h√¨nh</h2>
    <p>Ki·ªÉm tra ƒë·ªô ch√≠nh x√°c tr√™n t·∫≠p ki·ªÉm tra:</p>
    
      loss, accuracy = model.evaluate(X, y)
      print(f'Loss: {loss:.4f}, Accuracy: {accuracy:.4f}')
<br>
    <h2>B∆∞·ªõc 7: D·ª± ƒëo√°n v√† nh·∫≠n di·ªán</h2>
    <p>D·ª± ƒëo√°n tr√™n ·∫£nh m·ªõi::</p>
    
      import cv2
      img = cv2.imread('/content/test_image.jpg')
      img = cv2.resize(img, (64, 64))
      img = np.expand_dims(img, axis=0) / 255.0
      
      prediction = model.predict(img)
      if prediction[0][0] > prediction[0][1]:
          print("Kh√¥ng ƒëeo kh·∫©u trang")
      else:
          print("ƒêeo kh·∫©u trang")

<br>

## ü§ù ƒê√≥ng g√≥p
D·ª± √°n ƒë∆∞·ª£c ph√°t tri·ªÉn b·ªüi 3 th√†nh vi√™n:

| H·ªç v√† T√™n                | Vai tr√≤                  |
|--------------------------|--------------------------|
| V≈© Ng·ªçc Ti·∫øn            | Ph√°t tri·ªÉn to√†n b·ªô m√£ ngu·ªìn,ki·ªÉm th·ª≠, tri·ªÉn khai d·ª± √°n , thuy·∫øt tr√¨nh, ƒë·ªÅ xu·∫•t c·∫£i ti·∫øn.|
| L∆∞∆°ng Anh V≈©            | Bi√™n so·∫°n t√†i li·ªáu Overleaf ,h·ªó tr·ª£ b√†i t·∫≠p l·ªõn.|
| L√™ Nguy·ªÖn Kh√°nh T√πng    | H·ªó tr·ª£ b√†i t·∫≠p l·ªõn ,Powerpoint v√† th·ª±c hi·ªán video gi·ªõi thi·ªáu.  |

¬© 2025 NH√ìM 3, CNTT 17-15, TR∆Ø·ªúNG ƒê·∫†I H·ªåC ƒê·∫†I NAM
